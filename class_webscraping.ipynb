{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1eb295-02a2-4b9b-b9cd-2282df5b1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=0\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=10\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=20\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=30\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=40\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=50\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=60\n",
      "Fetching URL: https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc&from=70\n",
      "Article is older than 2025-01-01. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'positive_sentiment': 0.139,\n",
       "  'negative_sentiment': 0.018,\n",
       "  'neutral_sentiment': 0.843,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4623,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 23)},\n",
       " {'positive_sentiment': 0.151,\n",
       "  'negative_sentiment': 0.049,\n",
       "  'neutral_sentiment': 0.801,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4352,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 22)},\n",
       " {'positive_sentiment': 0.137,\n",
       "  'negative_sentiment': 0.026,\n",
       "  'neutral_sentiment': 0.837,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3036,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 22)},\n",
       " {'positive_sentiment': 0.128,\n",
       "  'negative_sentiment': 0.014,\n",
       "  'neutral_sentiment': 0.858,\n",
       "  'compound_sentiment': 0.9997,\n",
       "  'word_count': 2322,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 22)},\n",
       " {'positive_sentiment': 0.151,\n",
       "  'negative_sentiment': 0.023,\n",
       "  'neutral_sentiment': 0.827,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3296,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 22)},\n",
       " {'positive_sentiment': 0.134,\n",
       "  'negative_sentiment': 0.022,\n",
       "  'neutral_sentiment': 0.844,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2392,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 22)},\n",
       " {'positive_sentiment': 0.116,\n",
       "  'negative_sentiment': 0.003,\n",
       "  'neutral_sentiment': 0.88,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2873,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'and',\n",
       "  'date': datetime.date(2025, 1, 22)},\n",
       " {'positive_sentiment': 0.132,\n",
       "  'negative_sentiment': 0.024,\n",
       "  'neutral_sentiment': 0.844,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3574,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 21)},\n",
       " {'positive_sentiment': 0.137,\n",
       "  'negative_sentiment': 0.022,\n",
       "  'neutral_sentiment': 0.841,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4628,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 21)},\n",
       " {'positive_sentiment': 0.134,\n",
       "  'negative_sentiment': 0.011,\n",
       "  'neutral_sentiment': 0.855,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2098,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 21)},\n",
       " {'positive_sentiment': 0.1,\n",
       "  'negative_sentiment': 0.018,\n",
       "  'neutral_sentiment': 0.882,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 5326,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 21)},\n",
       " {'positive_sentiment': 0.122,\n",
       "  'negative_sentiment': 0.047,\n",
       "  'neutral_sentiment': 0.831,\n",
       "  'compound_sentiment': 0.9997,\n",
       "  'word_count': 3309,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 20)},\n",
       " {'positive_sentiment': 0.137,\n",
       "  'negative_sentiment': 0.058,\n",
       "  'neutral_sentiment': 0.805,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4560,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 20)},\n",
       " {'positive_sentiment': 0.139,\n",
       "  'negative_sentiment': 0.034,\n",
       "  'neutral_sentiment': 0.827,\n",
       "  'compound_sentiment': 1.0,\n",
       "  'word_count': 5686,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 20)},\n",
       " {'positive_sentiment': 0.144,\n",
       "  'negative_sentiment': 0.029,\n",
       "  'neutral_sentiment': 0.828,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4448,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 18)},\n",
       " {'positive_sentiment': 0.185,\n",
       "  'negative_sentiment': 0.01,\n",
       "  'neutral_sentiment': 0.805,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 2112,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 18)},\n",
       " {'positive_sentiment': 0.134,\n",
       "  'negative_sentiment': 0.027,\n",
       "  'neutral_sentiment': 0.839,\n",
       "  'compound_sentiment': 0.9997,\n",
       "  'word_count': 2405,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 18)},\n",
       " {'positive_sentiment': 0.136,\n",
       "  'negative_sentiment': 0.025,\n",
       "  'neutral_sentiment': 0.838,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2828,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 18)},\n",
       " {'positive_sentiment': 0.156,\n",
       "  'negative_sentiment': 0.029,\n",
       "  'neutral_sentiment': 0.815,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4439,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 18)},\n",
       " {'positive_sentiment': 0.152,\n",
       "  'negative_sentiment': 0.03,\n",
       "  'neutral_sentiment': 0.819,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3417,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 17)},\n",
       " {'positive_sentiment': 0.135,\n",
       "  'negative_sentiment': 0.026,\n",
       "  'neutral_sentiment': 0.839,\n",
       "  'compound_sentiment': 0.9997,\n",
       "  'word_count': 2169,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 17)},\n",
       " {'positive_sentiment': 0.16,\n",
       "  'negative_sentiment': 0.023,\n",
       "  'neutral_sentiment': 0.817,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 2971,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.104,\n",
       "  'negative_sentiment': 0.024,\n",
       "  'neutral_sentiment': 0.872,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 7374,\n",
       "  'top_word_1': 'the',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': '.',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.14,\n",
       "  'negative_sentiment': 0.012,\n",
       "  'neutral_sentiment': 0.848,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3083,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.164,\n",
       "  'negative_sentiment': 0.046,\n",
       "  'neutral_sentiment': 0.79,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3916,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.14,\n",
       "  'negative_sentiment': 0.028,\n",
       "  'neutral_sentiment': 0.833,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3787,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.142,\n",
       "  'negative_sentiment': 0.04,\n",
       "  'neutral_sentiment': 0.817,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4689,\n",
       "  'top_word_1': 'the',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.153,\n",
       "  'negative_sentiment': 0.006,\n",
       "  'neutral_sentiment': 0.842,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 2521,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 15)},\n",
       " {'positive_sentiment': 0.151,\n",
       "  'negative_sentiment': 0.016,\n",
       "  'neutral_sentiment': 0.834,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2356,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 14)},\n",
       " {'positive_sentiment': 0.129,\n",
       "  'negative_sentiment': 0.034,\n",
       "  'neutral_sentiment': 0.837,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2808,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 14)},\n",
       " {'positive_sentiment': 0.125,\n",
       "  'negative_sentiment': 0.012,\n",
       "  'neutral_sentiment': 0.863,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2551,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 14)},\n",
       " {'positive_sentiment': 0.134,\n",
       "  'negative_sentiment': 0.038,\n",
       "  'neutral_sentiment': 0.828,\n",
       "  'compound_sentiment': 0.9996,\n",
       "  'word_count': 2159,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 14)},\n",
       " {'positive_sentiment': 0.127,\n",
       "  'negative_sentiment': 0.032,\n",
       "  'neutral_sentiment': 0.841,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3429,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 14)},\n",
       " {'positive_sentiment': 0.106,\n",
       "  'negative_sentiment': 0.019,\n",
       "  'neutral_sentiment': 0.875,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3476,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 14)},\n",
       " {'positive_sentiment': 0.123,\n",
       "  'negative_sentiment': 0.026,\n",
       "  'neutral_sentiment': 0.852,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3355,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 13)},\n",
       " {'positive_sentiment': 0.153,\n",
       "  'negative_sentiment': 0.002,\n",
       "  'neutral_sentiment': 0.845,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2054,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 13)},\n",
       " {'positive_sentiment': 0.133,\n",
       "  'negative_sentiment': 0.007,\n",
       "  'neutral_sentiment': 0.859,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2338,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 13)},\n",
       " {'positive_sentiment': 0.149,\n",
       "  'negative_sentiment': 0.038,\n",
       "  'neutral_sentiment': 0.813,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4492,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 13)},\n",
       " {'positive_sentiment': 0.155,\n",
       "  'negative_sentiment': 0.032,\n",
       "  'neutral_sentiment': 0.814,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4002,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 13)},\n",
       " {'positive_sentiment': 0.135,\n",
       "  'negative_sentiment': 0.028,\n",
       "  'neutral_sentiment': 0.837,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4350,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 13)},\n",
       " {'positive_sentiment': 0.141,\n",
       "  'negative_sentiment': 0.037,\n",
       "  'neutral_sentiment': 0.822,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4045,\n",
       "  'top_word_1': 'the',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 11)},\n",
       " {'positive_sentiment': 0.142,\n",
       "  'negative_sentiment': 0.046,\n",
       "  'neutral_sentiment': 0.812,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3929,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 10)},\n",
       " {'positive_sentiment': 0.13,\n",
       "  'negative_sentiment': 0.073,\n",
       "  'neutral_sentiment': 0.797,\n",
       "  'compound_sentiment': 0.9997,\n",
       "  'word_count': 4460,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 10)},\n",
       " {'positive_sentiment': 0.154,\n",
       "  'negative_sentiment': 0.033,\n",
       "  'neutral_sentiment': 0.813,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3990,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'and',\n",
       "  'date': datetime.date(2025, 1, 9)},\n",
       " {'positive_sentiment': 0.168,\n",
       "  'negative_sentiment': 0.009,\n",
       "  'neutral_sentiment': 0.824,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 2288,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 9)},\n",
       " {'positive_sentiment': 0.101,\n",
       "  'negative_sentiment': 0.012,\n",
       "  'neutral_sentiment': 0.887,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3224,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 9)},\n",
       " {'positive_sentiment': 0.18,\n",
       "  'negative_sentiment': 0.016,\n",
       "  'neutral_sentiment': 0.805,\n",
       "  'compound_sentiment': 1.0,\n",
       "  'word_count': 5760,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 9)},\n",
       " {'positive_sentiment': 0.129,\n",
       "  'negative_sentiment': 0.028,\n",
       "  'neutral_sentiment': 0.843,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3811,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 9)},\n",
       " {'positive_sentiment': 0.156,\n",
       "  'negative_sentiment': 0.042,\n",
       "  'neutral_sentiment': 0.802,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3131,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 9)},\n",
       " {'positive_sentiment': 0.128,\n",
       "  'negative_sentiment': 0.038,\n",
       "  'neutral_sentiment': 0.834,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3162,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.172,\n",
       "  'negative_sentiment': 0.019,\n",
       "  'neutral_sentiment': 0.809,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 1830,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.128,\n",
       "  'negative_sentiment': 0.049,\n",
       "  'neutral_sentiment': 0.823,\n",
       "  'compound_sentiment': 0.9996,\n",
       "  'word_count': 2443,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.137,\n",
       "  'negative_sentiment': 0.04,\n",
       "  'neutral_sentiment': 0.822,\n",
       "  'compound_sentiment': 0.9996,\n",
       "  'word_count': 1967,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.122,\n",
       "  'negative_sentiment': 0.049,\n",
       "  'neutral_sentiment': 0.828,\n",
       "  'compound_sentiment': 0.9997,\n",
       "  'word_count': 3631,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.142,\n",
       "  'negative_sentiment': 0.031,\n",
       "  'neutral_sentiment': 0.827,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3299,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.16,\n",
       "  'negative_sentiment': 0.008,\n",
       "  'neutral_sentiment': 0.832,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3948,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 8)},\n",
       " {'positive_sentiment': 0.133,\n",
       "  'negative_sentiment': 0.021,\n",
       "  'neutral_sentiment': 0.846,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2440,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 7)},\n",
       " {'positive_sentiment': 0.129,\n",
       "  'negative_sentiment': 0.043,\n",
       "  'neutral_sentiment': 0.827,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3671,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 7)},\n",
       " {'positive_sentiment': 0.172,\n",
       "  'negative_sentiment': 0.006,\n",
       "  'neutral_sentiment': 0.822,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3494,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'and',\n",
       "  'date': datetime.date(2025, 1, 7)},\n",
       " {'positive_sentiment': 0.109,\n",
       "  'negative_sentiment': 0.037,\n",
       "  'neutral_sentiment': 0.854,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 5020,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 7)},\n",
       " {'positive_sentiment': 0.095,\n",
       "  'negative_sentiment': 0.028,\n",
       "  'neutral_sentiment': 0.877,\n",
       "  'compound_sentiment': 1.0,\n",
       "  'word_count': 10845,\n",
       "  'top_word_1': ',',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'and',\n",
       "  'date': datetime.date(2025, 1, 7)},\n",
       " {'positive_sentiment': 0.12,\n",
       "  'negative_sentiment': 0.031,\n",
       "  'neutral_sentiment': 0.849,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3503,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 7)},\n",
       " {'positive_sentiment': 0.164,\n",
       "  'negative_sentiment': 0.02,\n",
       "  'neutral_sentiment': 0.817,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 2921,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 6)},\n",
       " {'positive_sentiment': 0.148,\n",
       "  'negative_sentiment': 0.021,\n",
       "  'neutral_sentiment': 0.831,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3316,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 6)},\n",
       " {'positive_sentiment': 0.118,\n",
       "  'negative_sentiment': 0.017,\n",
       "  'neutral_sentiment': 0.865,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3525,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 6)},\n",
       " {'positive_sentiment': 0.103,\n",
       "  'negative_sentiment': 0.015,\n",
       "  'neutral_sentiment': 0.881,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 5028,\n",
       "  'top_word_1': 'the',\n",
       "  'top_word_2': '.',\n",
       "  'top_word_3': 'of',\n",
       "  'date': datetime.date(2025, 1, 6)},\n",
       " {'positive_sentiment': 0.152,\n",
       "  'negative_sentiment': 0.039,\n",
       "  'neutral_sentiment': 0.809,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3647,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 6)},\n",
       " {'positive_sentiment': 0.145,\n",
       "  'negative_sentiment': 0.0,\n",
       "  'neutral_sentiment': 0.855,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2268,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 4)},\n",
       " {'positive_sentiment': 0.159,\n",
       "  'negative_sentiment': 0.032,\n",
       "  'neutral_sentiment': 0.808,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3596,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 3)},\n",
       " {'positive_sentiment': 0.109,\n",
       "  'negative_sentiment': 0.04,\n",
       "  'neutral_sentiment': 0.85,\n",
       "  'compound_sentiment': 0.9995,\n",
       "  'word_count': 2503,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 2)},\n",
       " {'positive_sentiment': 0.167,\n",
       "  'negative_sentiment': 0.044,\n",
       "  'neutral_sentiment': 0.789,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2319,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'to',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 2)},\n",
       " {'positive_sentiment': 0.128,\n",
       "  'negative_sentiment': 0.023,\n",
       "  'neutral_sentiment': 0.849,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 4629,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': ',',\n",
       "  'top_word_3': 'the',\n",
       "  'date': datetime.date(2025, 1, 2)},\n",
       " {'positive_sentiment': 0.131,\n",
       "  'negative_sentiment': 0.04,\n",
       "  'neutral_sentiment': 0.83,\n",
       "  'compound_sentiment': 0.9999,\n",
       "  'word_count': 3617,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': ',',\n",
       "  'date': datetime.date(2025, 1, 2)},\n",
       " {'positive_sentiment': 0.122,\n",
       "  'negative_sentiment': 0.047,\n",
       "  'neutral_sentiment': 0.831,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 3939,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'a',\n",
       "  'date': datetime.date(2025, 1, 1)},\n",
       " {'positive_sentiment': 0.147,\n",
       "  'negative_sentiment': 0.029,\n",
       "  'neutral_sentiment': 0.824,\n",
       "  'compound_sentiment': 0.9998,\n",
       "  'word_count': 2549,\n",
       "  'top_word_1': '.',\n",
       "  'top_word_2': 'the',\n",
       "  'top_word_3': 'to',\n",
       "  'date': datetime.date(2025, 1, 1)}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "class NewsScraper:\n",
    "    def __init__(self, base_url, until_date=None, days_ago=None):\n",
    "        \"\"\"\n",
    "        Initializes the web scraping object with the given base URL and optional date parameters.\n",
    "\n",
    "        Args:\n",
    "            base_url (str): The base URL for the web scraping.\n",
    "            until_date (str, optional): The end date for the web scraping in 'YYYY-MM-DD' format. Defaults to None.\n",
    "            days_ago (int, optional): The number of days ago from today to set the end date. Defaults to None.\n",
    "\n",
    "        Attributes:\n",
    "            base_url (str): The base URL for the web scraping.\n",
    "            until_date (str): The calculated end date for the web scraping.\n",
    "            news_data (list): A list to store the scraped news data.\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        self.until_date = self.set_until_date(until_date, days_ago)\n",
    "        self.news_data = []\n",
    "\n",
    "    def set_until_date(self, until_date, days_ago):\n",
    "        \"\"\"\n",
    "        Set the 'until_date' based on the provided parameters.\n",
    "\n",
    "        Parameters:\n",
    "        until_date (str or datetime.date or None): The target date until which to set. \n",
    "            If a string is provided, it should be in 'YYYY-MM-DD' format.\n",
    "            If None, the date will be calculated based on 'days_ago'.\n",
    "        days_ago (int or None): The number of days ago from today to set the 'until_date'.\n",
    "            If None, defaults to 30 days ago.\n",
    "\n",
    "        Returns:\n",
    "        datetime.date: The calculated 'until_date'.\n",
    "\n",
    "        Raises:\n",
    "        ValueError: If 'until_date' is a string but not in the correct 'YYYY-MM-DD' format.\n",
    "        TypeError: If 'until_date' is not a string or datetime.date object.\n",
    "\n",
    "        Notes:\n",
    "        - If both 'until_date' and 'days_ago' are None, the function defaults to 30 days ago.\n",
    "        - If an error occurs, the function prints an error message and defaults to 30 days ago.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if until_date is None and days_ago is not None:\n",
    "                return datetime.now().date() - timedelta(days=days_ago)\n",
    "            elif until_date is None:\n",
    "                return datetime.now().date() - timedelta(days=30)\n",
    "            else:\n",
    "                if isinstance(until_date, str):\n",
    "                    try:\n",
    "                        return datetime.strptime(until_date, '%Y-%m-%d').date()\n",
    "                    except ValueError:\n",
    "                        raise ValueError(\"until_date is not in the correct format (expected 'YYYY-MM-DD').\")\n",
    "                elif not isinstance(until_date, datetime.date):\n",
    "                    raise TypeError(\"until_date must be a string in 'YYYY-MM-DD' format or a datetime.date object.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting until_date: {e}\")\n",
    "            return datetime.now().date() - timedelta(days=30)\n",
    "\n",
    "    def convert_date(self, date_str):\n",
    "        \"\"\"\n",
    "        Converts a relative or absolute date string into a date object.\n",
    "        The function handles relative date strings such as \"2 days ago\", \"3 hours ago\",\n",
    "        \"15 minutes ago\", and \"1 week ago\". It also handles absolute date strings in the\n",
    "        format \"Month Day, Year\" (e.g., \"January 1, 2020\").\n",
    "        Args:\n",
    "            date_str (str): The date string to convert.\n",
    "        Returns:\n",
    "            date: A date object representing the converted date, or None if the conversion fails.\n",
    "        Raises:\n",
    "            ValueError: If the date string is in an unrecognized format.\n",
    "            Exception: For any other exceptions that occur during conversion.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if \"day\" in date_str:\n",
    "                days_ago = int(date_str.split()[0])\n",
    "                return (datetime.now() - timedelta(days=days_ago)).date()\n",
    "            elif \"hour\" in date_str:\n",
    "                hours_ago = int(date_str.split()[0])\n",
    "                return (datetime.now() - timedelta(hours=hours_ago)).date()\n",
    "            elif \"minute\" in date_str:\n",
    "                minutes_ago = int(date_str.split()[0])\n",
    "                return (datetime.now() - timedelta(minutes=minutes_ago)).date()\n",
    "            elif \"week\" in date_str:\n",
    "                weeks_ago = int(date_str.split()[0])\n",
    "                return (datetime.now() - timedelta(weeks=weeks_ago)).date()\n",
    "\n",
    "            try:\n",
    "                return datetime.strptime(date_str.strip(), '%B %d, %Y').date()\n",
    "            except ValueError as ve:\n",
    "                print(f\"ValueError while parsing date: {date_str}. Error: {ve}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting date: {date_str}. Exception: {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_news(self):\n",
    "        \"\"\"\n",
    "        Scrapes news articles from the specified base URL with pagination.\n",
    "        This method fetches news articles by sending HTTP GET requests to the base URL with an offset parameter.\n",
    "        It parses the HTML content to extract article details such as title, link, excerpt, and date.\n",
    "        The method continues to paginate until no more articles are found or an article older than the specified `until_date` is encountered.\n",
    "        Returns:\n",
    "            list: A list of dictionaries, each containing the following keys:\n",
    "                - 'title' (str): The title of the article.\n",
    "                - 'link' (str): The full URL to the article.\n",
    "                - 'excerpt' (str): A brief excerpt of the article.\n",
    "                - 'date' (datetime.date): The publication date of the article.\n",
    "        Raises:\n",
    "            ValueError: If the date string cannot be parsed and `convert_date` method also fails to convert it.\n",
    "        Notes:\n",
    "            - The method uses a User-Agent header to mimic a browser request.\n",
    "            - The method prints debug information such as the URL being fetched and any errors encountered during parsing.\n",
    "            - The method stops pagination if no more articles are found or if an article is older than the specified `until_date`.\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        \n",
    "        while True:\n",
    "            url = f\"{self.base_url}&from={offset}\"\n",
    "            print(f\"Fetching URL: {url}\")\n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            articles = soup.find_all('a', {'class': 'article-card__link'})\n",
    "            \n",
    "            if not articles:\n",
    "                print(\"No more articles found. Stopping pagination.\")\n",
    "                break\n",
    "\n",
    "            for article in articles:\n",
    "                title_tag = article.find('h3', {'class': 'article-card__headline'})\n",
    "                excerpt_tag = article.find('p', {'class': 'article-card__excerpt'})\n",
    "                meta_bottom_tag = article.find_next('div', {'class': 'article-card__meta-bottom'})\n",
    "                date_tag = meta_bottom_tag.find('span', {'class': 'article-card__time-clamp'}) if meta_bottom_tag else None\n",
    "\n",
    "                if not date_tag:\n",
    "                    print(\"HTML of the article without a date:\")\n",
    "                    print(article.prettify())\n",
    "                    continue\n",
    "\n",
    "                title = title_tag.get_text(strip=True) if title_tag else None\n",
    "                link = article['href'] if article.has_attr('href') else None\n",
    "                excerpt = excerpt_tag.get_text(strip=True) if excerpt_tag else None\n",
    "                date_str = date_tag.get_text(strip=True) if date_tag else None\n",
    "\n",
    "                date = None\n",
    "                if date_str:\n",
    "                    try:\n",
    "                        date = parse(date_str).date()\n",
    "                    except ValueError:\n",
    "                        date = self.convert_date(date_str)\n",
    "                        if date is None:\n",
    "                            print(f\"Error parsing date with convert_date: {date_str}. Skipping this article.\")\n",
    "                            continue\n",
    "\n",
    "                if self.until_date and date and isinstance(date, datetime):\n",
    "                    date = date.date()\n",
    "                if self.until_date and date < self.until_date:\n",
    "                    print(f\"Article is older than {self.until_date}. Stopping.\")\n",
    "                    return self.news_data\n",
    "\n",
    "                if title and link:\n",
    "                    self.news_data.append({\n",
    "                        'title': title,\n",
    "                        'link': f\"https://financialpost.com{link}\",\n",
    "                        'excerpt': excerpt,\n",
    "                        'date': date\n",
    "                    })\n",
    "\n",
    "            offset += 10\n",
    "\n",
    "        return self.news_data\n",
    "\n",
    "    def get_article_content(self, link):\n",
    "        \"\"\"\n",
    "        Retrieves the content of an article from the given URL.\n",
    "        This method sends a GET request to the specified link with a custom User-Agent header.\n",
    "        If the request is successful (status code 200), it parses the HTML content using BeautifulSoup\n",
    "        and extracts text from all <p> tags within <div>, <section>, or <article> tags. If a <p> tag\n",
    "        contains a <strong> tag, the text within the <strong> tag is given priority.\n",
    "        Args:\n",
    "            link (str): The URL of the article to retrieve.\n",
    "        Returns:\n",
    "            str: The extracted article content as a single string, or None if the request failed.\n",
    "        Raises:\n",
    "            requests.exceptions.RequestException: If there is an issue with the network request.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        response = requests.get(link, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            possible_content = soup.find_all(['div', 'section', 'article'])\n",
    "\n",
    "            content = \"\"\n",
    "            for content_section in possible_content:\n",
    "                paragraphs = content_section.find_all('p')\n",
    "                for para in paragraphs:\n",
    "                    strong_text = para.find('strong')\n",
    "                    if strong_text:\n",
    "                        content += strong_text.get_text(strip=True) + \" \"\n",
    "                    content += para.get_text(strip=True) + \" \"\n",
    "            \n",
    "            return content.strip()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve the article. Status code: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    def process_news(self, news_data):\n",
    "        processed_news = []\n",
    "\n",
    "\n",
    "        for news in news_data:\n",
    "            title = news['title']\n",
    "            link = news['link']\n",
    "            date = news['date']  # Verkrijg de datum hier\n",
    "\n",
    "            # Scrape the article content\n",
    "            content = self.get_article_content(link)\n",
    "\n",
    "            # Append enriched data, inclusief de datum\n",
    "            processed_news.append({\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'content': content,\n",
    "                'date': date  # Voeg de datum toe aan de verwerkte data\n",
    "            })\n",
    "\n",
    "        return processed_news\n",
    "    def extract_features(self, news_data):\n",
    "        \"\"\"\n",
    "        Converts news content into numerical features for stock prediction.\n",
    "\n",
    "        Args:\n",
    "            news_data (list): A list of dictionaries containing news data with 'content' and 'title'.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries with numerical features extracted from the news content.\n",
    "        \"\"\"\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        feature_data = []\n",
    "\n",
    "        for news in news_data:\n",
    "            title = news.get('title', '')\n",
    "            content = news.get('content', '')\n",
    "\n",
    "            # Use content if available, otherwise fall back to title\n",
    "            text = content if content else title\n",
    "\n",
    "            # Sentiment scores\n",
    "            sentiment = sia.polarity_scores(text)\n",
    "\n",
    "            # Tokenization and lemmatization\n",
    "            tokens = word_tokenize(text)\n",
    "            lemmatized_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "\n",
    "            # Word frequency (top 3 most common words)\n",
    "            word_counts = Counter(lemmatized_tokens)\n",
    "            top_words = word_counts.most_common(3)\n",
    "\n",
    "            # Feature dictionary\n",
    "            features = {\n",
    "                'positive_sentiment': sentiment['pos'],\n",
    "                'negative_sentiment': sentiment['neg'],\n",
    "                'neutral_sentiment': sentiment['neu'],\n",
    "                'compound_sentiment': sentiment['compound'],\n",
    "                'word_count': len(tokens),\n",
    "                'top_word_1': top_words[0][0] if len(top_words) > 0 else None,\n",
    "                'top_word_2': top_words[1][0] if len(top_words) > 1 else None,\n",
    "                'top_word_3': top_words[2][0] if len(top_words) > 2 else None,\n",
    "                'date': news.get('date', None)\n",
    "            }\n",
    "\n",
    "            feature_data.append(features)\n",
    "\n",
    "        return feature_data\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute the entire workflow: scrape news, process, and extract features.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries containing numerical features for stock prediction.\n",
    "        \"\"\"\n",
    "        news_data = self.scrape_news()\n",
    "        processed_news = self.process_news(news_data)\n",
    "        feature_data = self.extract_features(processed_news)\n",
    "        return feature_data\n",
    "\n",
    "# Example run\n",
    "scraper = NewsScraper(base_url='https://financialpost.com/search/?search_text=S%26P+500&date_range=-3650d&sort=desc', until_date='2025-01-01')\n",
    "features = scraper.run()\n",
    "display(features)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37b213-836f-44dc-8509-be7af12d4d65",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 1. CPI (Consumer Price Index)\n",
    "\n",
    "### What It Is\n",
    "- The CPI measures the average change in prices paid by consumers for a basket of goods and services over time.\n",
    "- It is a key indicator of inflation and cost-of-living changes.\n",
    "\n",
    "### Why It’s Important\n",
    "- CPI helps economists, policymakers, and investors understand inflation trends.\n",
    "- Rising CPI indicates inflation, meaning the purchasing power of money decreases.\n",
    "- Changes in CPI can influence interest rates, stock market trends, and economic policies.\n",
    "\n",
    "### How It’s Calculated\n",
    "1. Identify a fixed basket of goods and services typically consumed by households.\n",
    "2. Track the price of each item in the basket over time.\n",
    "3. Calculate the cost of the basket for a given period.\n",
    "4. Compare the cost to a base year and express the change as a percentage.\n",
    "\n",
    "Mathematically:  \n",
    "\n",
    "$$\n",
    "CPI = \\frac{\n",
    "    \\sum_{i=1}^{n} \n",
    "    \\left( \\frac{\n",
    "        \\text{Price of Basket in Current Year}_i\n",
    "    }{\n",
    "        \\text{Price of Basket in Base Year}_i\n",
    "    } \\right)\n",
    "}{n} \\times 100\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **Cost of Basket at Current Period**: Sum of current prices of all items in the basket.\n",
    "- **Cost of Basket at Base Period**: Sum of prices of the same items in the base year.\n",
    "\n",
    "---\n",
    "Fernando, J. (2024b, 24 oktober). Consumer Price Index (CPI): What It Is and How It's Used. Investopedia. https://www.investopedia.com/terms/c/consumerpriceindex.asp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a29023-3bd8-46f9-85d3-8d27a7ba9ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
